{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Store Fashion Retail Sales Analysis - EDA\n",
    "## January 2024 Exploratory Data Analysis\n",
    "\n",
    "**Analyst**: Data Analysis Team\n",
    "\n",
    "**Date**: October 2025\n",
    "\n",
    "**Objective**: Conduct comprehensive exploratory analysis of sales data from 8 fashion retail stores across Japan to identify seasonal patterns, emerging trends, and performance insights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization parameters for high-quality charts\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"Libraries loaded successfully\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "DATA_DIR = Path('../data/processed')\n",
    "REPORTS_DIR = Path('../reports/assets')\n",
    "\n",
    "# Create reports/assets directory if it doesn't exist\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load processed datasets\n",
    "sales_df = pd.read_csv(DATA_DIR / 'sales_clean.csv', parse_dates=['date'])\n",
    "stores_df = pd.read_csv(DATA_DIR / 'stores.csv')\n",
    "products_df = pd.read_csv(DATA_DIR / 'products.csv')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"\\nSales transactions: {len(sales_df):,} rows\")\n",
    "print(f\"Stores: {len(stores_df)} stores\")\n",
    "print(f\"Product categories: {len(products_df)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview and Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of each dataset\n",
    "print(\"=\"*80)\n",
    "print(\"SALES DATA SAMPLE\")\n",
    "print(\"=\"*80)\n",
    "display(sales_df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STORES DATA\")\n",
    "print(\"=\"*80)\n",
    "display(stores_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRODUCTS DATA\")\n",
    "print(\"=\"*80)\n",
    "display(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and info\n",
    "print(\"=\"*80)\n",
    "print(\"SALES DATA INFO\")\n",
    "print(\"=\"*80)\n",
    "sales_df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\"*80)\n",
    "missing = sales_df.isnull().sum()\n",
    "missing_pct = (missing / len(sales_df) * 100).round(2)\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "display(missing_summary[missing_summary['Missing Count'] > 0])\n",
    "\n",
    "print(\"\\nNote: quantity field has some missing values, which is acceptable per data requirements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of sales data\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "display(sales_df[['sales_amount', 'quantity', 'day_of_month', 'week_of_month']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Business Metrics Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key business metrics\n",
    "total_revenue = sales_df['sales_amount'].sum()\n",
    "total_transactions = len(sales_df)\n",
    "avg_transaction_value = sales_df['sales_amount'].mean()\n",
    "median_transaction_value = sales_df['sales_amount'].median()\n",
    "num_stores_with_sales = sales_df['store_id'].nunique()\n",
    "date_range = f\"{sales_df['date'].min().strftime('%Y-%m-%d')} to {sales_df['date'].max().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"KEY BUSINESS METRICS - JANUARY 2024\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Revenue:              ¥{total_revenue:,.0f}\")\n",
    "print(f\"Total Transactions:         {total_transactions:,}\")\n",
    "print(f\"Average Transaction Value:  ¥{avg_transaction_value:,.0f}\")\n",
    "print(f\"Median Transaction Value:   ¥{median_transaction_value:,.0f}\")\n",
    "print(f\"Active Stores:              {num_stores_with_sales} out of 10\")\n",
    "print(f\"Date Range:                 {date_range}\")\n",
    "print(f\"Days in Period:             {sales_df['date'].dt.date.nunique()} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Store Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sales with store information\n",
    "sales_with_stores = sales_df.merge(stores_df, on='store_id', how='left')\n",
    "\n",
    "# Revenue by store\n",
    "store_revenue = sales_with_stores.groupby(['store_id', 'store_name_en', 'region']).agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "store_revenue.columns = ['store_id', 'store_name', 'region', 'total_revenue', 'avg_transaction', 'num_transactions']\n",
    "store_revenue = store_revenue.sort_values('total_revenue', ascending=False)\n",
    "store_revenue['revenue_share_pct'] = (store_revenue['total_revenue'] / store_revenue['total_revenue'].sum() * 100).round(2)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"REVENUE BY STORE (Ranked)\")\n",
    "print(\"=\"*80)\n",
    "display(store_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue by region\n",
    "region_revenue = sales_with_stores.groupby('region').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count'],\n",
    "    'store_id': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "region_revenue.columns = ['region', 'total_revenue', 'avg_transaction', 'num_transactions', 'num_stores']\n",
    "region_revenue = region_revenue.sort_values('total_revenue', ascending=False)\n",
    "region_revenue['revenue_share_pct'] = (region_revenue['total_revenue'] / region_revenue['total_revenue'].sum() * 100).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REVENUE BY REGION (Ranked)\")\n",
    "print(\"=\"*80)\n",
    "display(region_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Product Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue by product category\n",
    "category_revenue = sales_df.groupby('product_category').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "category_revenue.columns = ['category', 'total_revenue', 'avg_transaction', 'num_transactions']\n",
    "category_revenue = category_revenue.sort_values('total_revenue', ascending=False)\n",
    "category_revenue['revenue_share_pct'] = (category_revenue['total_revenue'] / category_revenue['total_revenue'].sum() * 100).round(2)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"REVENUE BY PRODUCT CATEGORY\")\n",
    "print(\"=\"*80)\n",
    "display(category_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category performance by store\n",
    "category_by_store = sales_with_stores.groupby(['store_name_en', 'product_category'])['sales_amount'].sum().unstack(fill_value=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CATEGORY REVENUE BY STORE (¥)\")\n",
    "print(\"=\"*80)\n",
    "display(category_by_store.style.format('¥{:,.0f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily revenue trend\n",
    "daily_revenue = sales_df.groupby('date')['sales_amount'].sum().reset_index()\n",
    "daily_revenue.columns = ['date', 'revenue']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DAILY REVENUE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Average Daily Revenue:    ¥{daily_revenue['revenue'].mean():,.0f}\")\n",
    "print(f\"Median Daily Revenue:     ¥{daily_revenue['revenue'].median():,.0f}\")\n",
    "print(f\"Highest Daily Revenue:    ¥{daily_revenue['revenue'].max():,.0f} on {daily_revenue.loc[daily_revenue['revenue'].idxmax(), 'date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Lowest Daily Revenue:     ¥{daily_revenue['revenue'].min():,.0f} on {daily_revenue.loc[daily_revenue['revenue'].idxmin(), 'date'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "display(daily_revenue.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week analysis\n",
    "# Define proper day order\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "dow_revenue = sales_df.groupby('day_of_week').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "dow_revenue.columns = ['day_of_week', 'total_revenue', 'avg_transaction', 'num_transactions']\n",
    "\n",
    "# Sort by custom day order\n",
    "dow_revenue['day_of_week'] = pd.Categorical(dow_revenue['day_of_week'], categories=day_order, ordered=True)\n",
    "dow_revenue = dow_revenue.sort_values('day_of_week')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REVENUE BY DAY OF WEEK\")\n",
    "print(\"=\"*80)\n",
    "display(dow_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekend vs Weekday comparison\n",
    "weekend_comparison = sales_df.groupby('is_weekend').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "weekend_comparison.columns = ['is_weekend', 'total_revenue', 'avg_transaction', 'num_transactions']\n",
    "weekend_comparison['period'] = weekend_comparison['is_weekend'].map({True: 'Weekend', False: 'Weekday'})\n",
    "\n",
    "# Calculate average per day\n",
    "weekend_days = sales_df[sales_df['is_weekend']]['date'].dt.date.nunique()\n",
    "weekday_days = sales_df[~sales_df['is_weekend']]['date'].dt.date.nunique()\n",
    "\n",
    "weekend_comparison['avg_revenue_per_day'] = weekend_comparison.apply(\n",
    "    lambda row: row['total_revenue'] / (weekend_days if row['is_weekend'] else weekday_days), axis=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WEEKEND vs WEEKDAY PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "display(weekend_comparison[['period', 'total_revenue', 'avg_transaction', 'num_transactions', 'avg_revenue_per_day']])\n",
    "\n",
    "# Calculate weekend lift\n",
    "weekend_avg = weekend_comparison[weekend_comparison['is_weekend']]['avg_revenue_per_day'].values[0]\n",
    "weekday_avg = weekend_comparison[~weekend_comparison['is_weekend']]['avg_revenue_per_day'].values[0]\n",
    "weekend_lift = ((weekend_avg - weekday_avg) / weekday_avg * 100)\n",
    "\n",
    "print(f\"\\nWeekend Lift: {weekend_lift:+.1f}% higher average daily revenue than weekdays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week of month analysis\n",
    "week_revenue = sales_df.groupby('week_of_month').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "week_revenue.columns = ['week_of_month', 'total_revenue', 'avg_transaction', 'num_transactions']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REVENUE BY WEEK OF MONTH\")\n",
    "print(\"=\"*80)\n",
    "display(week_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations\n",
    "\n",
    "Now we'll create professional visualizations to communicate our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Daily Revenue Trend\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(daily_revenue['date'], daily_revenue['revenue'], marker='o', linewidth=2, markersize=6, color='#2E86AB')\n",
    "ax.axhline(y=daily_revenue['revenue'].mean(), color='red', linestyle='--', linewidth=1.5, label='Average Daily Revenue', alpha=0.7)\n",
    "\n",
    "ax.set_title('Daily Revenue Trend - January 2024', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Revenue (¥)', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000:.0f}K'))\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'daily_revenue_trend.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: daily_revenue_trend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Revenue by Store\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = sns.color_palette('viridis', len(store_revenue))\n",
    "bars = ax.barh(store_revenue['store_name'], store_revenue['total_revenue'], color=colors)\n",
    "\n",
    "# Add revenue labels on bars\n",
    "for i, (bar, revenue, pct) in enumerate(zip(bars, store_revenue['total_revenue'], store_revenue['revenue_share_pct'])):\n",
    "    ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, \n",
    "            f'  ¥{revenue/1000000:.1f}M ({pct}%)', \n",
    "            va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_title('Total Revenue by Store - January 2024', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Revenue (¥)', fontsize=12)\n",
    "ax.set_ylabel('Store', fontsize=12)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000000:.1f}M'))\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'revenue_by_store.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: revenue_by_store.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Revenue by Region\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = sns.color_palette('Set2', len(region_revenue))\n",
    "bars = ax.bar(region_revenue['region'], region_revenue['total_revenue'], color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add revenue labels on bars\n",
    "for bar, revenue, pct in zip(bars, region_revenue['total_revenue'], region_revenue['revenue_share_pct']):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height,\n",
    "            f'¥{revenue/1000000:.1f}M\\n({pct}%)',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_title('Total Revenue by Region - January 2024', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Region', fontsize=12)\n",
    "ax.set_ylabel('Revenue (¥)', fontsize=12)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000000:.1f}M'))\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'revenue_by_region.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: revenue_by_region.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Revenue by Product Category\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = sns.color_palette('pastel', len(category_revenue))\n",
    "bars = ax.barh(category_revenue['category'], category_revenue['total_revenue'], color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add revenue labels\n",
    "for bar, revenue, pct in zip(bars, category_revenue['total_revenue'], category_revenue['revenue_share_pct']):\n",
    "    ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2,\n",
    "            f'  ¥{revenue/1000000:.1f}M ({pct}%)',\n",
    "            va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_title('Total Revenue by Product Category - January 2024', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Revenue (¥)', fontsize=12)\n",
    "ax.set_ylabel('Product Category', fontsize=12)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000000:.1f}M'))\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'revenue_by_category.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: revenue_by_category.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 5: Revenue by Day of Week\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Color weekends differently\n",
    "colors = ['#A6CEE3' if day in ['Saturday', 'Sunday'] else '#1F78B4' for day in dow_revenue['day_of_week']]\n",
    "bars = ax.bar(dow_revenue['day_of_week'], dow_revenue['total_revenue'], color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add revenue labels\n",
    "for bar, revenue in zip(bars, dow_revenue['total_revenue']):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height,\n",
    "            f'¥{revenue/1000000:.1f}M',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_title('Total Revenue by Day of Week - January 2024', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Day of Week', fontsize=12)\n",
    "ax.set_ylabel('Revenue (¥)', fontsize=12)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000000:.1f}M'))\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add legend for weekday vs weekend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='#1F78B4', label='Weekday'),\n",
    "                   Patch(facecolor='#A6CEE3', label='Weekend')]\n",
    "ax.legend(handles=legend_elements, loc='upper left')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'revenue_by_day_of_week.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: revenue_by_day_of_week.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 6: Weekend vs Weekday Comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Revenue comparison\n",
    "colors_1 = ['#2E86AB', '#A23B72']\n",
    "bars1 = ax1.bar(weekend_comparison['period'], weekend_comparison['total_revenue'], color=colors_1, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for bar, revenue in zip(bars1, weekend_comparison['total_revenue']):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, height,\n",
    "             f'¥{revenue/1000000:.1f}M',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax1.set_title('Total Revenue: Weekend vs Weekday', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Revenue (¥)', fontsize=11)\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000000:.1f}M'))\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Transaction count comparison\n",
    "bars2 = ax2.bar(weekend_comparison['period'], weekend_comparison['num_transactions'], color=colors_1, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for bar, count in zip(bars2, weekend_comparison['num_transactions']):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, height,\n",
    "             f'{int(count):,}',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax2.set_title('Transaction Count: Weekend vs Weekday', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Number of Transactions', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "fig.suptitle('Weekend vs Weekday Performance - January 2024', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'weekend_vs_weekday.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: weekend_vs_weekday.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 7: Category Performance by Store (Stacked Bar)\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Prepare data for stacked bar\n",
    "category_by_store_pct = category_by_store.div(category_by_store.sum(axis=1), axis=0) * 100\n",
    "\n",
    "category_by_store_pct.plot(kind='barh', stacked=True, ax=ax, \n",
    "                           colormap='Set3', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_title('Product Category Mix by Store (% of Store Revenue) - January 2024', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Percentage of Store Revenue (%)', fontsize=12)\n",
    "ax.set_ylabel('Store', fontsize=12)\n",
    "ax.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'category_mix_by_store.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: category_mix_by_store.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 8: Top and Bottom Performers\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Top 4 stores\n",
    "top_stores = store_revenue.head(4)\n",
    "colors_top = sns.color_palette('Greens_d', len(top_stores))[::-1]\n",
    "bars1 = ax1.barh(top_stores['store_name'], top_stores['total_revenue'], color=colors_top, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for bar, revenue, pct in zip(bars1, top_stores['total_revenue'], top_stores['revenue_share_pct']):\n",
    "    ax1.text(bar.get_width(), bar.get_y() + bar.get_height()/2,\n",
    "             f'  ¥{revenue/1000000:.1f}M ({pct}%)',\n",
    "             va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax1.set_title('Top 4 Performing Stores', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Revenue (¥)', fontsize=11)\n",
    "ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000000:.1f}M'))\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Bottom 4 stores\n",
    "bottom_stores = store_revenue.tail(4)\n",
    "colors_bottom = sns.color_palette('Reds_d', len(bottom_stores))\n",
    "bars2 = ax2.barh(bottom_stores['store_name'], bottom_stores['total_revenue'], color=colors_bottom, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for bar, revenue, pct in zip(bars2, bottom_stores['total_revenue'], bottom_stores['revenue_share_pct']):\n",
    "    ax2.text(bar.get_width(), bar.get_y() + bar.get_height()/2,\n",
    "             f'  ¥{revenue/1000000:.1f}M ({pct}%)',\n",
    "             va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax2.set_title('Bottom 4 Performing Stores', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Revenue (¥)', fontsize=11)\n",
    "ax2.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'¥{x/1000000:.1f}M'))\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "fig.suptitle('Store Performance Benchmarking - January 2024', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'top_bottom_stores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Chart saved: top_bottom_stores.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights Summary\n",
    "\n",
    "Based on the exploratory analysis, here are the preliminary key insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate specific metrics for insights\n",
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS - PRELIMINARY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Insight 1: Regional concentration\n",
    "kanto_revenue = region_revenue[region_revenue['region'] == 'Kanto']['total_revenue'].values[0]\n",
    "kanto_pct = region_revenue[region_revenue['region'] == 'Kanto']['revenue_share_pct'].values[0]\n",
    "print(f\"\\n1. REGIONAL CONCENTRATION\")\n",
    "print(f\"   Kanto region generates ¥{kanto_revenue/1000000:.1f}M ({kanto_pct}%) of total revenue\")\n",
    "print(f\"   with {region_revenue[region_revenue['region'] == 'Kanto']['num_stores'].values[0]} stores\")\n",
    "\n",
    "# Insight 2: Top store performance\n",
    "top_store = store_revenue.iloc[0]\n",
    "print(f\"\\n2. TOP STORE LEADERSHIP\")\n",
    "print(f\"   {top_store['store_name']} leads with ¥{top_store['total_revenue']/1000000:.1f}M ({top_store['revenue_share_pct']}% market share)\")\n",
    "print(f\"   Average transaction value: ¥{top_store['avg_transaction']:,.0f}\")\n",
    "\n",
    "# Insight 3: Category dominance\n",
    "top_category = category_revenue.iloc[0]\n",
    "print(f\"\\n3. CATEGORY PERFORMANCE\")\n",
    "print(f\"   {top_category['category']} dominates with ¥{top_category['total_revenue']/1000000:.1f}M ({top_category['revenue_share_pct']}%)\")\n",
    "print(f\"   {top_category['num_transactions']:,.0f} transactions at ¥{top_category['avg_transaction']:,.0f} average\")\n",
    "\n",
    "# Insight 4: Weekend performance\n",
    "print(f\"\\n4. WEEKEND PERFORMANCE LIFT\")\n",
    "print(f\"   Weekend daily revenue averages ¥{weekend_avg/1000:.0f}K vs weekday ¥{weekday_avg/1000:.0f}K\")\n",
    "print(f\"   Weekend lift: {weekend_lift:+.1f}%\")\n",
    "\n",
    "# Insight 5: Store performance gap\n",
    "top_store_rev = store_revenue.iloc[0]['total_revenue']\n",
    "bottom_store_rev = store_revenue.iloc[-1]['total_revenue']\n",
    "performance_gap = ((top_store_rev - bottom_store_rev) / bottom_store_rev * 100)\n",
    "print(f\"\\n5. PERFORMANCE GAP\")\n",
    "print(f\"   Top performer ({store_revenue.iloc[0]['store_name']}) generates {performance_gap:.0f}% more\")\n",
    "print(f\"   revenue than lowest performer ({store_revenue.iloc[-1]['store_name']})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendations Preview\n",
    "\n",
    "Preliminary recommendations for Q2 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PRELIMINARY RECOMMENDATIONS FOR Q2 2024\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. WEEKEND OPTIMIZATION\")\n",
    "print(f\"   Given {weekend_lift:+.1f}% weekend lift, consider:\")\n",
    "print(\"   - Extended weekend hours at top performing stores\")\n",
    "print(\"   - Weekend-specific promotions and events\")\n",
    "print(\"   - Increased weekend staffing levels\")\n",
    "\n",
    "print(\"\\n2. REGIONAL STRATEGY\")\n",
    "print(f\"   Kanto dominance ({kanto_pct}% of revenue) suggests:\")\n",
    "print(\"   - Invest in underperforming regional stores (best practice sharing)\")\n",
    "print(\"   - Consider additional Kanto expansion given strong performance\")\n",
    "print(\"   - Regional marketing campaigns tailored to local preferences\")\n",
    "\n",
    "print(\"\\n3. CATEGORY FOCUS\")\n",
    "print(f\"   {top_category['category']} leadership ({top_category['revenue_share_pct']}%) indicates:\")\n",
    "print(\"   - Expand top category inventory and variety\")\n",
    "print(\"   - Cross-sell strategies to boost underperforming categories\")\n",
    "print(\"   - Category-specific seasonal planning for Q2-Q3\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Data Export for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export key summary tables for reporting\n",
    "store_revenue.to_csv('../reports/store_performance_summary.csv', index=False)\n",
    "region_revenue.to_csv('../reports/region_performance_summary.csv', index=False)\n",
    "category_revenue.to_csv('../reports/category_performance_summary.csv', index=False)\n",
    "\n",
    "print(\"Summary tables exported to reports/ directory\")\n",
    "print(\"  - store_performance_summary.csv\")\n",
    "print(\"  - region_performance_summary.csv\")\n",
    "print(\"  - category_performance_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This exploratory data analysis has revealed several actionable insights about January 2024 sales performance across 8 fashion retail stores in Japan:\n",
    "\n",
    "1. Strong regional concentration in Kanto\n",
    "2. Clear store performance hierarchy with opportunities for best practice sharing\n",
    "3. Dominant category performance patterns\n",
    "4. Significant weekend performance advantage\n",
    "5. Temporal patterns that can inform staffing and inventory decisions\n",
    "\n",
    "The next step is to compile these findings into a comprehensive analysis report with specific recommendations for Q2 2024.\n",
    "\n",
    "---\n",
    "\n",
    "**Visualizations Created**: 8 high-quality PNG files (300 DPI)\n",
    "\n",
    "**Next Steps**: Create detailed analysis_report.md and reusable analysis functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
